{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025d1e19",
   "metadata": {},
   "source": [
    "Let me guide you through creating a basic NLP pipeline using NLTK in Python. We'll be using the movie reviews dataset from NLTK for sentiment analysis. Here's a step-by-step guide:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c556294",
   "metadata": {},
   "source": [
    "1. Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bfda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0175fe5",
   "metadata": {},
   "source": [
    "2. Download the movie reviews dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff822f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\kamalap1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf38f5",
   "metadata": {},
   "source": [
    "3. Explore the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc89ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.categories())\n",
    "print(len(movie_reviews.fileids('pos')))\n",
    "print(len(movie_reviews.fileids('neg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378194a0",
   "metadata": {},
   "source": [
    "4. Prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d5a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie reviews documents\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6f0dc",
   "metadata": {},
   "source": [
    "5. Shuffle the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d64585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents\n",
    "import random\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f80aa",
   "metadata": {},
   "source": [
    "6. Normalize or tokenize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be63aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb2173",
   "metadata": {},
   "source": [
    "7. Split the dataset into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7240c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce36f6d",
   "metadata": {},
   "source": [
    "8. Train a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9430186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69ae96",
   "metadata": {},
   "source": [
    "9. Test the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb1ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00303984",
   "metadata": {},
   "source": [
    "10. Show the most informative features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fae785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.3 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      9.0 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.8 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      7.6 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cce755",
   "metadata": {},
   "source": [
    "This script will give you a basic introduction to tokenization, stemming, and other NLP techniques using NLTK. It uses a Naive Bayes classifier for sentiment analysis on the movie reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79a9f1",
   "metadata": {},
   "source": [
    "let's create a test feature and use the classifier to predict the sentiment. We'll create a simple review and see how our classifier predicts its sentiment.\n",
    "\n",
    "Here is the additional Python code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c2daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "# Define a new review\n",
    "new_review = 'This movie was fantastic! The acting was great, plot was wonderful, and the ending was so satisfying'\n",
    "\n",
    "# Tokenize the new review\n",
    "new_review_tokens = nltk.word_tokenize(new_review)\n",
    "\n",
    "# Create the features for the new review\n",
    "new_review_features = document_features(new_review_tokens)\n",
    "\n",
    "# Use the classifier to predict the sentiment of the new review\n",
    "print(classifier.classify(new_review_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaad11b",
   "metadata": {},
   "source": [
    "This will print either 'pos' or 'neg' depending on whether the classifier thinks the new review is positive or negative.\n",
    "Remember, this is a very basic example. The accuracy of the classifier can be improved by using more sophisticated feature extraction techniques, using larger datasets, and tuning the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58c05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d816e",
   "metadata": {},
   "source": [
    "The review 'This movie was fantastic! The acting was great, plot was wonderful, and the ending was so satisfying' is indeed positive.\n",
    "\n",
    "The misclassification could be due to several reasons. One of the most common reasons is that the model may not have been trained on enough data to accurately classify sentiment. The model used in this example is quite basic and only uses the presence or absence of words in the review to classify its sentiment. This approach doesn't consider the context in which words are used, which can lead to misclassification.\n",
    "\n",
    "In addition to this, the model was trained on the top 2000 words from the movie_reviews corpus, which may not include all the words in the test review. If a word in the test review is not in the training set, the model won't know how to handle it.\n",
    "Another potential issue is that the model does not take into account the order of the words, which can also lead to misclassification. For example, the model would treat \"This movie is not good\" and \"Is this movie good?\" as the same, even though they express opposite sentiments.\n",
    "\n",
    "To improve the performance of the classifier, you could use more sophisticated NLP techniques such as using bigrams, trigrams or more advanced models like LSTM, or transformers which are capable of understanding the context of the words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfd833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
